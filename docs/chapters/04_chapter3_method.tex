% chapters/04_chapter3_method.tex
% Chapter 3: Methodology (Phương Pháp Nghiên Cứu)

\chapter{PHƯƠNG PHÁP NGHIÊN CỨU}
\label{chap:methodology}

Chương này trình bày chi tiết phương pháp nghiên cứu bao gồm môi trường mô phỏng, thiết kế hàm reward, kiến trúc mạng nơ-ron, quy trình huấn luyện, xây dựng robot thực tế, thiết kế các module điều khiển (PID), sensor fusion (UKF), mapping và localization (Cartographer SLAM), và triển khai hệ thống robot hoàn chỉnh.

\section{Môi trường mô phỏng}
\label{sec:environment}

Hệ đa robot tránh va chạm được huấn luyện trong môi trường mô phỏng dựa trên Stage simulator kết hợp với ROS (Robot Operating System). Bài toán điều khiển được mô hình hóa dưới dạng Partially Observable Markov Decision Process (POMDP), trong đó mỗi robot đưa ra quyết định dựa trên quan sát cục bộ của chính nó mà không cần giao tiếp với các robot khác.

\subsection{Không gian quan sát}

Tại thời điểm $t$, robot $i$ nhận được vector quan sát $o_t^i \in \mathcal{O}$ bao gồm ba thành phần:

\begin{equation}
o_t^i = [o_z^t, o_g^t, o_v^t]
\label{eq:observation}
\end{equation}

trong đó:

\textbf{Dữ liệu LiDAR} $o_z^t \in \mathbb{R}^{3 \times 454}$: Cảm biến quét 360 độ với 454 tia laser. Range được đặt giống với cảm biến trên robot thực tế: 0.03m - 5.5m. Mỗi phép đo trả về khoảng cách đến vật cản gần nhất theo hướng tương ứng.

\textbf{Vị trí đích} $o_g^t \in \mathbb{R}^2$: Tọa độ tương đối $(r, \theta)$ từ robot đến đích trong hệ tọa độ cục bộ của robot, với $r$ là khoảng cách và $\theta$ là góc lệch so với hướng robot.

\textbf{Vận tốc hiện tại} $o_v^t \in \mathbb{R}^2$: Vận tốc tuyến tính $v$ (m/s) và vận tốc góc $\omega$ (rad/s) của robot, giúp model nhận biết trạng thái chuyển động hiện tại.

\subsection{Không gian hành động}

Robot điều khiển chuyển động thông qua cặp hành động liên tục:

\begin{equation}
a_t = [v_t, \omega_t]
\label{eq:action}
\end{equation}

với $v_t \in [0, v_{\max}]$ là vận tốc tuyến tính giới hạn trong khoảng 0-0.3 m/s, và $\omega_t \in [-\omega_{\max}, \omega_{\max}]$ là vận tốc góc giới hạn trong $\pm 1.0$ rad/s. Mạng Actor xuất ra phân phối Gaussian $\mathcal{N}(\mu, \sigma^2)$ cho mỗi thành phần, sau đó lấy mẫu để thu được hành động cụ thể.

\section{Thiết kế hàm reward}
\label{sec:reward_design}

Hàm reward đóng vai trò quyết định trong việc định hình hành vi của robot. Reward function được thiết kế với mục tiêu cân bằng giữa hiệu quả (đến đích nhanh) và an toàn (tránh va chạm), đồng thời đảm bảo tín hiệu học tập rõ ràng không mâu thuẫn. Đồng thời kế thừa những ưu điểm đã được chứng minh ở bài báo gốc \cite{long2018towards}

\subsection{Terminal rewards}

Reward được cấp khi episode kết thúc:

\begin{itemize}[nosep]
\item $r_{\text{arrival}} = +30$: Đến đích thành công (trong vòng 0.3m từ goal)
\item $r_{\text{collision}} = -25$: Va chạm với vật cản hoặc robot khác
\item $r_{\text{timeout}} = -10$: Hết thời gian cho phép (180 giây)
\end{itemize}

Các giá trị terminal rewards được thiết kế mạnh hơn so với bài báo gốc (30/-25 thay vì 15/-15 \cite{long2018towards}) để tạo tín hiệu rõ ràng hơn cho quá trình học.

\subsection{Step rewards}

Tại mỗi bước thời gian $t$, reward được tính từ 4 thành phần:

\begin{equation}
r_t = r_{\text{progress}} + r_{\text{safety}} + r_{\text{rotation}} + r_{\text{heading}}
\label{eq:reward}
\end{equation}

\textbf{Progress reward} khuyến khích robot tiến về phía đích. Nếu khoảng cách đến đích giảm từ $d_{t-1}$ xuống $d_t$, robot nhận được reward tỷ lệ với độ tiến bộ:

\begin{equation}
r_{\text{progress}} = 2.0 \times (d_{t-1} - d_t)
\end{equation}

Hệ số 2.0 (thấp hơn 2.5 trong bài báo gốc) giúp robot ưu tiên an toàn hơn tốc độ.

\textbf{Safety reward} áp dụng penalty khi robot đi quá nhanh ở khu vực gần vật cản. Hệ thống 2 vùng được thiết kế dựa trên khoảng cách gần nhất $d_{\min}$ đến vật cản:

\begin{equation}
r_{\text{safety}} = \begin{cases}
-0.3 \times (v_t - 0.2) & \text{if } d_{\min} < 0.35\text{m and } v_t > 0.2\\
-0.1 \times (v_t - 0.4) & \text{if } 0.35 \leq d_{\min} < 0.6\text{m and } v_t > 0.4\\
0 & \text{otherwise}
\end{cases}
\end{equation}

Logic: ở khu vực nguy hiểm (<0.35m), phạt mạnh nếu vận tốc vượt 0.2 m/s; ở khu vực cảnh báo (0.35-0.6m), phạt nhẹ nếu vận tốc vượt 0.4 m/s. Gradient mượt này giúp robot học cách điều chỉnh tốc độ theo mức độ nguy hiểm.

\textbf{Rotation penalty} hạn chế xoay quá nhanh để tránh chuyển động không mượt:

\begin{equation}
r_{\text{rotation}} = \begin{cases}
-0.06 \times |\omega_t| & \text{if } |\omega_t| > 0.8 \text{ rad/s}\\
0 & \text{otherwise}
\end{cases}
\end{equation}

Ngưỡng 0.8 rad/s và hệ số phạt -0.06 (nhẹ hơn -0.1 trong bài báo gốc) cho phép robot chuyển hướng dễ dàng hơn khi gặp vật cản.

\textbf{Heading reward} khuyến khích robot hướng về phía đích:

\begin{equation}
r_{\text{heading}} = \begin{cases}
0.15 \times (1 - |\theta_{\text{goal}}|/\pi) & \text{if } |\theta_{\text{goal}}|/\pi < 0.3\\
0 & \text{otherwise}
\end{cases}
\end{equation}

với $\theta_{\text{goal}}$ là góc lệch giữa hướng robot và hướng tới đích. Reward này giúp robot chủ động hướng về đích thay vì chỉ phụ thuộc vào progress reward.

\subsection{Điểm khác biệt so với bài báo gốc}

So với Long et al. (2018) \cite{long2018towards}, thiết kế reward có 3 cải tiến chính:

\begin{enumerate}[nosep]
\item \textbf{Terminal rewards mạnh hơn:} 30/-25 thay vì 15/-15 tạo tín hiệu rõ ràng hơn
\item \textbf{Safety reward 2 vùng:} Thay vì 1 ngưỡng cứng, gradient mượt giúp học tốt hơn
\item \textbf{Heading reward bổ sung:} Khuyến khích robot chủ động hướng về đích
\end{enumerate}

\section{Kiến trúc mạng nơ-ron}
\label{sec:network}

Kiến trúc Actor-Critic với encoder chung được sử dụng để xử lý dữ liệu laser scan và tạo ra cả chính sách hành động (Actor) và ước lượng giá trị trạng thái (Critic). Thiết kế này cho phép chia sẻ feature representations giữa Actor và Critic, tăng hiệu quả học tập.

\subsection{Encoder chung - Xử lý LiDAR}

Dữ liệu laser scan đầu vào $o_z^t \in \mathbb{R}^{3 \times 454}$ được xử lý qua 2 lớp convolution 1D:

\begin{itemize}[nosep]
\item \textbf{Conv1D Layer 1:} 32 filters, kernel size 5, stride 2, theo sau bởi ReLU
\item \textbf{Conv1D Layer 2:} 32 filters, kernel size 3, stride 2, theo sau bởi ReLU
\end{itemize}

Sau khi flatten, output của convolution có chiều khoảng 3600 dimensions được nén xuống qua fully connected layer với 256 neurons. Các lớp convolution này trích xuất đặc trưng không gian từ laser scans: kernel size 5 ở layer đầu học các pattern rộng hơn (nhóm obstacles), kernel size 3 ở layer thứ hai tinh chỉnh các detail. Stride 2 giúp giảm chiều dữ liệu nhanh để tránh overfitting.

Hình \ref{fig:network_architecture} minh họa kiến trúc mạng Actor-Critic hoàn chỉnh với các thành phần chính và luồng dữ liệu.

\begin{figure}[htbp]
\centering
\resizebox{0.95\textwidth}{!}{
\begin{tikzpicture}[
    node distance=1cm,
    box/.style={rectangle, draw, minimum width=2.2cm, minimum height=0.7cm, align=center, font=\small},
    input/.style={box, fill=blue!15, thick},
    conv/.style={box, fill=orange!25, thick},
    fc/.style={box, fill=green!25, thick},
    output/.style={box, fill=red!25, thick},
    arrow/.style={->, >=stealth, very thick}
]

% Input layer (left side)
\node[input] (laser) {LiDAR\\$3 \times 454$};
\node[input, below=0.5cm of laser] (goal) {Goal\\$(r, \theta)$};
\node[input, below=0.4cm of goal] (vel) {Velocity\\$(v, \omega)$};

% Encoder (Shared) - horizontal flow
\node[conv, right=1.8cm of laser] (conv1) {Conv1D\\32×5, s=2};
\node[conv, right=1.3cm of conv1] (conv2) {Conv1D\\32×3, s=2};
\node[fc, right=1.3cm of conv2] (flatten) {Flatten\\FC 256};

% Concat point
\node[right=1cm of flatten] (split) {};

% Actor branch (upper)
\node[fc, above right=0.3cm and 1.5cm of split] (actor_fc) {FC 128 + ReLU};
\node[output, right=1.3cm of actor_fc] (actor_out) {Actor output\\$\mu_v, \mu_\omega$};

% Critic branch (lower)
\node[fc, below right=0.3cm and 1.5cm of split] (critic_fc) {FC 128 + ReLU};
\node[output, right=1.3cm of critic_fc] (critic_out) {Critic output\\$V(s)$};

% Arrows - Main encoder path
\draw[arrow] (laser) -- (conv1);
\draw[arrow] (conv1) -- (conv2);
\draw[arrow] (conv2) -- (flatten);
\draw[arrow] (flatten) -- (split);

% Arrows - Goal and velocity bypass
\draw[arrow, blue!60] (goal.east) -- ++(0.8,0) |- (actor_fc.west);
\draw[arrow, blue!60] (vel.east) -- ++(0.8,0) |- (actor_fc.west);
\draw[arrow, blue!60] (goal.east) -- ++(0.8,0) |- (critic_fc.west);
\draw[arrow, blue!60] (vel.east) -- ++(0.8,0) |- (critic_fc.west);

% Arrows - Actor branch
\draw[arrow] (split) |- (actor_fc);
\draw[arrow] (actor_fc) -- (actor_out);

% Arrows - Critic branch
\draw[arrow] (split) |- (critic_fc);
\draw[arrow] (critic_fc) -- (critic_out);

% Section labels with background
\node[above=0.15cm of laser, font=\small\bfseries, fill=white] {Inputs};
\node[above=0.15cm of conv1, font=\small\bfseries, fill=white] {Shared Encoder};
\node[above=0.15cm of actor_fc, font=\small\bfseries, fill=white] {Actor Head};
\node[above=0.15cm of critic_fc, font=\small\bfseries, fill=white] {Critic Head};

\end{tikzpicture}
}
\caption{Kiến trúc mạng Actor-Critic với encoder chung. LiDAR data được xử lý qua 2 lớp Conv1D và FC layer tạo thành encoder chung, sau đó kết hợp với goal và velocity để tạo ra Actor (policy network) và Critic (value network) với các FC layers riêng biệt.}
\label{fig:network_architecture}
\end{figure}

\subsection{Mạng Actor - Sinh policy}

Output của encoder được kết hợp với vị trí đích $(r, \theta)$ và vận tốc hiện tại $(v, \omega)$, sau đó đi qua:

\begin{itemize}[nosep]
\item Fully connected layer 128 neurons + ReLU
\item Output layer: 2 neurons (mean values cho $v$ và $\omega$)
\item Separate learnable log-standard deviation parameters
\end{itemize}

Actor xuất ra phân phối Gaussian cho mỗi chiều của action:
\begin{equation}
\pi(a_t | o_t) = \mathcal{N}(\mu_\theta(o_t), \sigma_\theta^2)
\end{equation}

với $\mu_\theta$ là giá trị mean được tính từ mạng neural, và $\sigma_\theta = \exp(\text{log\_std})$ với log\_std là tham số độc lập được học. Mean value $\mu_v$ cho vận tốc tuyến tính đi qua sigmoid để giới hạn trong $[0, v_{\max}]$, còn $\mu_\omega$ cho vận tốc góc đi qua tanh để giới hạn trong $[-\omega_{\max}, \omega_{\max}]$.

\subsection{Mạng Critic - Ước lượng giá trị}

Critic sử dụng chung encoder với Actor nhưng có output head riêng:

\begin{itemize}[nosep]
\item Concatenate encoder output với goal và velocity
\item Fully connected layer 128 neurons + ReLU
\item Output layer: 1 neuron (value estimate)
\end{itemize}

Critic ước lượng value function:
\begin{equation}
V_\phi(o_t) \approx \mathbb{E}\left[\sum_{k=0}^{\infty} \gamma^k r_{t+k} \mid o_t\right]
\end{equation}

với $\gamma$ là discount factor. Value này được sử dụng để tính advantage function trong thuật toán PPO.

\subsection{Các kỹ thuật cải tiến}

So với kiến trúc trong bài báo gốc \cite{long2018towards}, một số kỹ thuật được bổ sung để cải thiện hiệu năng huấn luyện:

\textbf{1. Orthogonal initialization:} Trọng số được khởi tạo theo phương pháp orthogonal thay vì Xavier initialization tiêu chuẩn. Phương pháp này khởi tạo ma trận trọng số sao cho các cột trực giao với nhau, giúp gradient flow tốt hơn trong giai đoạn đầu huấn luyện và tránh vanishing/exploding gradient. Cụ thể, với ma trận $W \in \mathbb{R}^{m \times n}$, các cột được normalize sao cho $W^T W = I_n$, đảm bảo các activation không bị co hoặc giãn quá mức khi truyền qua các layer.

\textbf{2. Observation normalization:} Input laser scans được chuẩn hóa theo running mean và standard deviation, giúp ổn định quá trình học. Statistics được update liên tục trong training theo công thức: $\mu_{new} = 0.99 \mu_{old} + 0.01 \mu_{batch}$, đảm bảo model nhận input ở scale nhất quán.

\textbf{3. Separate optimizers:} Hai Adam optimizers riêng biệt với learning rates khác nhau được sử dụng cho Critic (6e-3) và Actor (4e-4). Critic learning rate cao hơn 15 lần giúp value network học nhanh hơn và cung cấp ước lượng chính xác cho policy updates, trong khi Actor learning rate thấp hơn để tránh policy thay đổi quá nhanh gây mất ổn định.

\textbf{4. Log-std clamping:} Log\_std được giới hạn trong khoảng $[-2.5, -0.8]$, tương đương standard deviation trong khoảng $[0.082, 0.449]$. Điều này ngăn policy trở nên quá deterministic (không khám phá đủ) hoặc quá stochastic (hành động quá random).

Tổng số parameters của model khoảng 150K, với phần lớn nằm ở encoder và các fully connected layers. Kiến trúc này đủ lớn để học các pattern phức tạp trong môi trường đa robot nhưng vẫn đủ nhỏ để huấn luyện được với hardware giới hạn.

\section{Quy trình huấn luyện}
\label{sec:training}

\subsection{Chiến lược huấn luyện 2 giai đoạn}

Áp dụng curriculum learning theo 2 stages tương tự Long et al. (2018) \cite{long2018towards} nhưng điều chỉnh cho phù hợp với môi trường Stage simulator và số lượng robots khác nhau. Các kịch bản huấn luyện đa dạng (đã mô tả ở Mục \ref{subsec:long_environment}) được sử dụng xuyên suốt quá trình training.

\textbf{Stage 1 - Foundation learning:} Huấn luyện24 robots trên môi trường cơ bản có ít vật cnả, học các hành vi cơ bản: tránh va chạm cục bộ, di chuyển về đích, điều chỉnh vận tốc. Hyperparameters ưu tiên exploration cao (entropy 8e-3) và learning rates mạnh (critic 6e-3, actor 4e-4) để khám phá không gian hành động nhanh.

\begin{figure}[htbp]
\centering
% \includegraphics[width=0.85\textwidth]{figures/stage1_circle_training.png}
\includegraphics[width=0.3\textwidth]{figures/obstacle.png}
\caption{Stage 1: môi trường đơn giản cho 24 robots}
\label{fig:stage1_training}
\end{figure}

\textbf{Stage 2 - Transfer learning:} Khởi tạo từ Stage 1 weights, tiếp tục huấn luyện 44 robots trên random scatter scenarios phức tạp hơn. Hình \ref{fig:stage2_training} (từ Long et al. 2018) cho thấy đa dạng tình huống. Hyperparameters điều chỉnh: tăng entropy (exploration nhiều hơn), giảm learning rates (critic 1e-3, actor 4e-4), tăng epochs lên 5, thêm value clipping để ổn định training với mật độ cao. 

\begin{figure}[htbp]
\centering
\includegraphics[width=0.65\textwidth]{figures/04_Fig8_training_scenarios.jpg}
\caption{Stage 2: 7 tình huống huấn luyện đa dạng từ đơn giản đến phức tạp giúp policy generalize tốt (nguồn: Long et al. 2018)}
\label{fig:stage2_training}
\end{figure}

\subsection{Thuật toán PPO với GAE}

Proximal Policy Optimization (PPO) được sử dụng với clipped surrogate objective để đảm bảo policy updates không quá lớn. Tại mỗi update, algorithm thực hiện:

\textbf{Bước 1 - Rollout:} Chạy policy hiện tại trong môi trường để thu thập trajectories $(o_t, a_t, r_t)$. Tổng cộng 400-800 timesteps mỗi update tùy số robots.

\textbf{Bước 2 - Compute advantages:} Tính Generalized Advantage Estimation (GAE) để ước lượng advantage function:
\begin{equation}
A_t = \sum_{l=0}^{\infty} (\gamma \lambda)^l \delta_{t+l}, \quad \delta_t = r_t + \gamma V(o_{t+1}) - V(o_t)
\end{equation}
với $\gamma$ = discount factor và $\lambda$ = GAE parameter cân bằng giữa bias và variance.

\textbf{Bước 3 - Policy update:} Tối ưu clipped objective function qua 3-5 epochs trên mini-batch data:
\begin{equation}
L^{\text{CLIP}}(\theta) = \mathbb{E}\left[\min(r_t(\theta) A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) A_t)\right]
\end{equation}
với $r_t(\theta) = \frac{\pi_\theta(a_t|o_t)}{\pi_{\theta_{\text{old}}}(a_t|o_t)}$ là probability ratio và $\epsilon$ = clip value.

\textbf{Bước 4 - Value update:} Cập nhật critic network với loss function bao gồm value clipping (cải tiến mới):
\begin{equation}
L^{\text{VF}}(\phi) = \mathbb{E}\left[\max\left((V_\phi(o_t) - V^{\text{target}})^2, (\text{clip}(V_\phi, V_{\text{old}} \pm \epsilon_v) - V^{\text{target}})^2\right)\right]
\end{equation}

Value clipping ngăn value function thay đổi quá nhanh, giúp training ổn định hơn đặc biệt trong môi trường multi-agent phức tạp.

\subsection{Hyperparameters chi tiết}

Bảng \ref{tab:stage1_hyperparams} và \ref{tab:stage2_hyperparams} liệt kê đầy đủ hyperparameters cho 2 giai đoạn huấn luyện.

\begin{table}[htbp]
\centering
\caption{Hyperparameters Stage 1 (20 robots - 74\% success)}
\label{tab:stage1_hyperparams}
\begin{tabular}{ll}
\hline
\textbf{Parameter} & \textbf{Value} \\
\hline
LAMDA ($\lambda$ - GAE) & 0.90 \\
GAMMA ($\gamma$ - discount factor) & 0.99 \\
EPOCH (training iterations per update) & 3 \\
COEFF\_ENTROPY (initial entropy bonus) & 8e-3 \\
ENTROPY\_MIN (minimum entropy) & 2e-3 \\
CLIP\_VALUE ($\epsilon$ - PPO clip) & 0.15 \\
CRITIC\_LR (learning rate) & 6e-3 \\
ACTOR\_LR (learning rate) & 4e-4 \\
value\_loss\_coeff & 5.0 \\
max\_grad\_norm (gradient clipping) & 1.0 \\
target\_kl (early stopping threshold) & 0.035 \\
\hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Hyperparameters Stage 2 (58 robots - 88\% test success)}
\label{tab:stage2_hyperparams}
\begin{tabular}{ll}
\hline
\textbf{Parameter} & \textbf{Value} \\
\hline
LAMDA ($\lambda$ - GAE) & 0.94 \\
GAMMA ($\gamma$ - discount factor) & 0.99 \\
EPOCH (training iterations per update) & 5 \\
COEFF\_ENTROPY (initial entropy bonus) & 7e-4 \\
ENTROPY\_MIN (minimum entropy) & 3e-3 \\
CLIP\_VALUE ($\epsilon$ - PPO clip) & 0.10 \\
CRITIC\_LR (learning rate) & 5e-4 \\
ACTOR\_LR (learning rate) & 1.5e-4 \\
value\_loss\_coeff & 3.5 \\
value\_clip & True \\
\hline
\end{tabular}
\end{table}

\subsection{Các kỹ thuật cải tiến được áp dụng}

So với Long et al. (2018) \cite{long2018towards}, 5 kỹ thuật cải tiến được áp dụng để tăng tốc convergence và ổn định training. Mỗi kỹ thuật được thiết kế để giải quyết một vấn đề cụ thể:

\subsubsection{Adaptive Learning Rate Scheduler}

\textbf{Vấn đề:} Fixed learning rate trong paper gốc gặp 2 vấn đề: (1) nếu giảm LR quá sớm khi performance đang cải thiện, sẽ làm chậm momentum; (2) nếu giữ LR cao khi stuck ở plateau, không thể thoát khỏi local minimum.

\textbf{Giải pháp:} Thiết kế adaptive LR scheduler với 2 nguyên tắc:
\begin{itemize}[nosep]
\item \textit{Maintain LR} khi performance window (20 updates gần nhất) đang cải thiện → không làm chậm momentum
\item \textit{Tăng LR} khi detect plateau (thay đổi < 2\% trong 60 updates) → thoát khỏi stuck state
\end{itemize}

\textbf{Cách hoạt động:} LR cao giúp escape saddle points và local minima, nhưng chỉ áp dụng khi thực sự cần (plateau), còn khi đang học tốt thì giữ nguyên để exploit momentum. Kết quả: training ổn định 200 updates không bị degradation, so với fixed LR thường cần 1000+ updates.

\subsubsection{Asymmetric Critic/Actor Training}

\textbf{Vấn đề:} Trong Actor-Critic, nếu critic (value function) học chậm, sẽ cung cấp value estimates không chính xác cho actor, dẫn đến policy updates theo sai hướng. Ngược lại, nếu actor updates quá nhanh, policy thay đổi đột ngột gây instability.

\textbf{Giải pháp:} Sử dụng 2 Adam optimizers riêng biệt với LR asymmetric:
\begin{itemize}[nosep]
\item Critic LR = 6e-3 (cao hơn 15× so với actor)
\item Actor LR = 4e-4 (thấp để tránh thay đổi đột ngột)
\end{itemize}

\textbf{Cách hoạt động:} Critic học nhanh hơn → value estimates converge sớm → cung cấp stable baseline cho policy gradient. Actor học chậm hơn → policy thay đổi  → tránh catastrophic forgetting. Trade-off này phù hợp với multi-agent environment phức tạp cần value function chính xác.

\subsubsection{Aggressive Exploration Strategy}

\textbf{Vấn đề:} Entropy coefficient thấp (1e-3 như paper gốc) khiến policy converge nhanh về deterministic policy, dẫn đến premature convergence - stuck ở solution tốt cục bộ nhưng không phải global optimum.

\textbf{Giải pháp:} Tăng entropy coefficient lên 8e-3 (10× cao hơn), decay dần xuống minimum 2e-3 theo schedule:
\begin{equation}
\text{entropy\_coeff}_t = \max(2 \times 10^{-3}, 8 \times 10^{-3} \times 0.995^t)
\end{equation}

\textbf{Cách hoạt động:} Entropy cao ban đầu khuyến khích khám phá diverse behaviors (nhiều cách tránh va chạm khác nhau), sau đó decay dần để policy exploit learned strategies. Điều này đặc biệt quan trọng trong multi-robot settings với exponential action space - cần explore đủ trước khi exploit.

\subsubsection{Value Function Clipping}

\textbf{Vấn đề:} Value function có thể thay đổi quá nhanh giữa các updates, gây instability cho advantage estimates, đặc biệt khi reward scale thay đổi nhiều (arrival +30, collision -25, timeout -10).

\textbf{Giải pháp:} Clip value function updates tương tự PPO policy clipping:
\begin{equation}
L^{VF}(\phi) = \max\left((V_\phi(o_t) - V^{\text{target}})^2, (\text{clip}(V_\phi, V_{\text{old}} \pm 0.2) - V^{\text{target}})^2\right)
\end{equation}

\textbf{Cách hoạt động:} Clipping ngăn value estimates nhảy vọt, giúp advantage $A = Q - V$ ổn định hơn, từ đó policy gradient direction đáng tin cậy hơn. Kỹ thuật này không có trong Long et al. (2018) nhưng được chứng minh hiệu quả trong PPO implementations sau này.

\subsubsection{Aggressive KL Early Stopping}

\textbf{Vấn đề:} KL divergence threshold quá thấp (1.5e-4 trong paper gốc) buộc policy updates rất nhỏ mỗi iteration, dẫn đến convergence chậm.

\textbf{Giải pháp:} Tăng target\_kl lên 0.035 (233× lớn hơn), cho phép policy updates mạnh hơn nhưng vẫn được kiểm soát bởi PPO clipping mechanism.

\textbf{Cách hoạt động:} PPO clipping đã ngăn policy thay đổi quá nhanh (clipped ở $[1-\epsilon, 1+\epsilon]$), nên KL threshold cao chỉ là safety net thứ hai. Threshold 0.035 cho phép policy explore aggressive hơn trong trust region mà không bị early stop quá sớm, tăng tốc learning từ 1000+ updates xuống 200 updates.

\vspace{0.5cm}
\textbf{Tổng kết:} 5 kỹ thuật trên cùng hoạt động để tạo training pipeline: (1) Adaptive LR tránh stuck, (2) Asymmetric training ổn định value estimates, (3) High entropy khám phá đủ, (4) Value clipping tránh instability, (5) Aggressive KL tăng tốc convergence. Trade-off: convergence nhanh hơn (200 vs 1000+ updates) nhưng cần monitoring cẩn thận.

\section{Xây dựng robot thực tế}
\label{sec:hardware_design}

Robot thực tế được thiết kế với mục tiêu deploy model đã huấn luyện lên phần cứng nhỏ gọn, chi phí thấp, phù hợp cho nghiên cứu multi-robot systems.

\subsection{Thông số kỹ thuật}

\textbf{Kích thước và cấu trúc:} Khung robot kích thước 20cm × 15.7cm được gia công từ tấm nhựa acrylic 5mm, thiết kế 2 tầng: tầng dưới chứa động cơ và mạch điều khiển, tầng trên đặt LiDAR và Jetson Nano. Khoảng cách giữa 2 bánh chủ động $L = 0.157$m được tính toán để cân bằng giữa maneuverability (rẽ gọn) và stability (không bị lật khi xoay nhanh).

\textbf{Hệ thống cảm biến:} LiDAR 360° được gắn ở trung tâm tầng trên với 455 beams, scan range ~12m, frequency 5-10Hz. LiDAR này tương thích trực tiếp với mô phỏng (cùng 455 tia laser), giúp giảm sim-to-real gap. IMU MPU6050 (gyroscope + accelerometer) đo góc xoay và gia tốc, fusion với wheel odometry qua UKF để ước lượng pose chính xác.

\textbf{Hệ thống điều khiển:} Jetson Nano (4GB RAM) chạy Ubuntu 18.04 và ROS Melodic, xử lý sensor fusion và serial communication với Arduino. Hai động cơ DC giảm tốc (tỷ số truyền 1:20) với encoder 15000 pulses/revolution điều khiển vận tốc bánh xe. Arduino nhận commands qua serial và điều khiển động cơ qua driver L298N.

\textbf{Nguồn điện:} Pin Li-Po 3S 11.1V 2200mAh cung cấp điện cho động cơ (qua voltage regulator 12V), và hạ áp 5V cho Jetson Nano. Thiết kế nguồn tách biệt tránh nhiễu điện từ động cơ ảnh hưởng đến tính toán.

\subsection{Kiến trúc phần mềm}

Hệ thống ROS gồm 5 nodes chính chạy song song: 
\begin{itemize}
  \item (1) \texttt{lidar\_node} publish laser scans
  \item (2) \texttt{imu\_node} publish IMU data
  \item (3) \texttt{odometry\_node} tính wheel odometry và fusion với IMU qua UKF
  \item (4) \texttt{policy\_node} load PyTorch model và inference action từ observations
  \item (5) \texttt{controller\_node} convert high-level actions $(v, \omega)$ sang PWM commands qua PID controllers.
\end{itemize}
Giao tiếp qua ROS topics đảm bảo tính đồng bộ: dễ thay thế policy mới hoặc upgrade sensors mà không ảnh hưởng toàn hệ thống.

\section{Thiết kế PID controller và chứng minh ổn định}
\label{sec:pid_stability}

Để điều khiển robot thực tế theo hành động đầu ra từ mạng neural $(v_{\text{ref}}, \omega_{\text{ref}})$, bộ điều khiển PID được thiết kế cho động cơ bánh xe. Phần này trình bày mô hình động học, thiết kế controller, chứng minh ổn định, và kết quả thực nghiệm.

\subsection{Mô hình động học differential drive robot}

Robot sử dụng cấu trúc differential drive với 2 bánh chủ động. Mô hình động học trong hệ tọa độ body frame:

\begin{equation}
\begin{bmatrix}
\dot{x} \\ \dot{y} \\ \dot{\theta}
\end{bmatrix} = \begin{bmatrix}
v \cos\theta \\ v \sin\theta \\ \omega
\end{bmatrix}
\label{eq:kinematics}
\end{equation}

với $(x, y, \theta)$ là pose của robot trong world frame. Vận tốc bánh trái và phải liên hệ với $(v, \omega)$ qua:

\begin{equation}
v_L = v - \frac{L\omega}{2}, \quad v_R = v + \frac{L\omega}{2}
\label{eq:wheel_velocity}
\end{equation}

với $L = 0.205$ m là khoảng cách giữa 2 bánh. Mỗi bánh được điều khiển bởi động cơ DC giảm tốc kèm encoder phản hồi, đo vận tốc dưới dạng encoder pulses per second.

\subsection{Thiết kế PID controller}

Cho mỗi bánh, PID controller riêng biệt được thiết kế theo công thức:

\begin{equation}
u(t) = K_p e(t) + K_i \int_0^t e(\tau) d\tau + K_d \frac{de(t)}{dt}
\label{eq:pid}
\end{equation}

với $e(t) = v_{\text{ref}}(t) - v_{\text{measured}}(t)$ là sai số vận tốc. Output $u(t)$ là tín hiệu PWM (Pulse Width Modulation) gửi đến driver động cơ.

Các tham số PID được tuning thông qua phương pháp trial-and-error với mục tiêu: (1) settling time < 3s, (2) overshoot < 5\%, (3) steady-state error < 2\%. Giá trị cuối cùng cho cả hai bánh là $K_p = 11.6$, $K_i = 4.9$, $K_d = 0.04$. Ba tham số này điều khiển: $K_p$ phản ứng tỷ lệ với lỗi hiện tại (chính), $K_i$ loại bỏ lỗi tích lũy lâu dài (phụ), $K_d$ giảm dao động bằng cách dự đoán xu hướng (nhỏ nhất).

\subsection{Phân tích ổn định}

Để phân tích tính ổn định của closed-loop system, mô hình động cơ DC được kết hợp với PID controller.

\textbf{Mô hình động cơ:} Động cơ DC giảm tốc được mô hình hóa gần đúng bằng hệ bậc nhất (first-order system):

\begin{equation}
\tau \dot{v} + v = K_m u
\label{eq:motor_model}
\end{equation}

với $\tau = 0.05$ s là time constant (đo từ thực nghiệm step response), $K_m = 0.8$ là motor gain (tỷ lệ giữa PWM và vận tốc đạt được), $v$ là vận tốc bánh xe (pulses/s), và $u$ là tín hiệu điều khiển PWM từ PID.

\textbf{Xác định tham số từ thực nghiệm:} Hai tham số $\tau$ và $K_m$ được xác định thông qua đo đạc trực tiếp trên động cơ (Hình \ref{fig:motor_params}).

\textit{Time constant $\tau$:} Để đo $\tau$, động cơ được cấp step input PWM và quan sát đáp ứng vận tốc. Theo lý thuyết hệ bậc nhất, $\tau$ là thời gian để vận tốc đạt 63.2\% giá trị ổn định. Hình \ref{fig:motor_params}(a) cho thấy đáp ứng step từ 0 → 100 pulses/s: tại thời điểm $t = 0.05$s, vận tốc đạt xấp xỉ 63.2 pulses/s (đúng 63.2\% của 100). Dữ liệu đo có nhiễu do encoder resolution và dao động cơ học, nhưng mô hình lý thuyết $v(t) = 100(1 - e^{-t/0.05})$ fit tốt với xu hướng chung. Giá trị $\tau = 0.05$s phù hợp với đặc tính động cơ DC giảm tốc (inertia thấp do tỷ số truyền, phản ứng nhanh).

\textit{Motor gain $K_m$:} Tham số $K_m$ thể hiện độ nhạy của vận tốc theo PWM ở chế độ ổn định. Hình \ref{fig:motor_params}(b) biểu diễn quan hệ giữa PWM command và vận tốc đo được tại 9 điểm khác nhau (PWM từ 10 đến 200). Các điểm đo có phân tán nhẹ do nhiễu sensor và ma sát thay đổi. Fitting tuyến tính cho $K_m \approx 0.81$ pulses/PWM. Để đơn giản hóa tính toán và làm tròn theo encoder specs (15000 pulses/rev, gear 1:20, PWM 8-bit), giá trị $K_m = 0.8$ được sử dụng trong mô hình.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{motor_parameter_identification.pdf}
\caption{Xác định tham số động cơ từ thực nghiệm. (a) Đáp ứng step để xác định time constant $\tau = 0.05$s: các điểm đo (xanh) có nhiễu nhẹ nhưng fit tốt với mô hình lý thuyết (đường xanh đậm); tại $t = \tau$, vận tốc đạt 63.2\% giá trị ổn định. (b) Quan hệ tuyến tính PWM-vận tốc để xác định motor gain: 9 điểm đo (đỏ) cho fitting $K_m \approx 0.81$, làm tròn thành $K_m = 0.8$ cho mô hình.}
\label{fig:motor_params}
\end{figure}

\textbf{Phân tích ổn định bằng Routh-Hurwitz:} Khi kết hợp PID controller với mô hình động cơ, closed-loop system tạo thành hệ bậc 3 với characteristic equation:

\begin{equation}
\tau s^3 + (1 + K_m K_d) s^2 + K_m K_p s + K_m K_i = 0
\label{eq:characteristic}
\end{equation}

Đặt các hệ số của phương trình đặc trưng: $a_0 = \tau = 0.05$, $a_1 = 1 + K_m K_d = 1.032$, $a_2 = K_m K_p = 9.28$, $a_3 = K_m K_i = 3.92$ (với $K_p = 11.6$, $K_i = 4.9$, $K_d = 0.04$, $K_m = 0.8$).

Xây dựng bảng Routh-Hurwitz:

\begin{table}[h]
\centering
\begin{tabular}{c|cc}
\hline
$s^3$ & $a_0 = 0.05$ & $a_2 = 9.28$ \\
$s^2$ & $a_1 = 1.032$ & $a_3 = 3.92$ \\
$s^1$ & $b_1 = \frac{a_1 a_2 - a_0 a_3}{a_1} = \frac{1.032 \times 9.28 - 0.05 \times 3.92}{1.032} = 9.29$ & $0$ \\
$s^0$ & $c_1 = a_3 = 3.92$ & \\
\hline
\end{tabular}
\caption{Bảng Routh-Hurwitz cho hệ PID bậc 3}
\label{tab:routh}
\end{table}

Điều kiện ổn định Routh-Hurwitz: tất cả phần tử cột đầu tiên phải cùng dấu (dương). Kiểm tra:
\begin{itemize}[nosep]
\item Hàng $s^3$: $a_0 = 0.05 > 0$ ✓
\item Hàng $s^2$: $a_1 = 1.032 > 0$ ✓
\item Hàng $s^1$: $b_1 = 9.29 > 0$ ✓
\item Hàng $s^0$: $c_1 = 3.92 > 0$ ✓
\end{itemize}

Tất cả phần tử cột đầu đều dương, do đó hệ thống ổn định. Không có pole nằm bên phải mặt phẳng phức hay trên trục ảo.

\subsection{Kết quả thực nghiệm}

Thử nghiệm step response được tiến hành trên robot thực tế với 6 setpoints khác nhau: 0.2, 0.4, 0.6, -0.3, -0.5, và 0 m/s. Kết quả đo được:

\textbf{Performance metrics:}
\begin{itemize}[nosep]
\item \textbf{Steady-state error:} Trung bình 0.5 pulses ($\approx$ 1.1\%), rất tốt
\item \textbf{Overshoot:} Tối đa 1.5\% (chỉ ở setpoint -0.3 m/s), đạt yêu cầu < 5\%
\item \textbf{Settling time:} Phần lớn < 1s, một số trường hợp 3-4s
\item \textbf{RMS error:} Từ 0.186 đến 3.756 pulses tùy setpoint
\end{itemize}

\textbf{Phân tích:} Các setpoint có magnitude lớn (0.4, 0.5 m/s) cho kết quả tốt nhất với settling time gần như tức thời và steady-state error < 1\%. Ngược lại, các setpoint nhỏ (0.2, -0.3 m/s) có settling time chậm hơn và oscillation lớn hơn (std dev 1.9-2.0 pulses). Điều này do ở vận tốc thấp, ma sát tĩnh và backlash trong hệ truyền động ảnh hưởng nhiều hơn. Setpoint 0 m/s (dừng) đạt hiệu suất xuất sắc với error gần như bằng 0.

\textbf{Kết luận:} Bộ PID đã thiết kế đạt mục tiêu điều khiển với steady-state error < 2\% và overshoot < 5\% ở hầu hết setpoints. Hệ thống ổn định theo phân tích Routh-Hurwitz và được xác nhận qua thực nghiệm. Performance ở vận tốc thấp có thể được cải thiện thông qua compensation cho ma sát tĩnh hoặc adaptive gains.

\section{Thiết kế sensor fusion với UKF}
\label{sec:ukf_implementation}

Để ước lượng chính xác pose và vận tốc của robot, Unscented Kalman Filter (UKF) được sử dụng để kết hợp dữ liệu từ IMU (gyroscope, accelerometer) và wheel odometry. UKF được chọn vì: (1) không cần tính Jacobian như EKF - tiết kiệm công sức cho nonlinear models, (2) cho độ chính xác cao hơn thông qua unscented transform, (3) computational cost chấp nhận được với Jetson Nano (~5ms/update ở 50Hz).

\subsection{Ý tưởng chính của UKF}

Thay vì linearize hệ phi tuyến như EKF, UKF sử dụng kỹ thuật \textbf{unscented transform}: chọn một tập các điểm đại diện (gọi là \textbf{sigma points}) xung quanh state estimate hiện tại, sau đó truyền từng điểm qua hàm phi tuyến để tính mean và covariance mới. Phương pháp này cho approximation chính xác hơn nhiều so với Taylor expansion bậc nhất của EKF, đặc biệt với hệ có nonlinearity cao như differential drive robot.

\subsection{Mô hình state và measurements}

\textbf{State vector} $\mathbf{x}_t = [x, y, \theta, v_x, v_y, \omega]^T \in \mathbb{R}^6$ mô tả đầy đủ trạng thái robot: pose $(x, y, \theta)$ trong world frame, vận tốc tuyến tính $(v_x, v_y)$ trong body frame, và vận tốc góc $\omega$.

\textbf{Process model} mô tả chuyển động robot theo differential drive kinematics (tương tự eq. \ref{eq:kinematics}). Tại mỗi bước, state được cập nhật dựa trên command velocity từ PID và thêm process noise để model uncertainty (slip, backlash):

\begin{equation}
\mathbf{x}_{t+1} = f(\mathbf{x}_t, \mathbf{u}_t) + \mathbf{w}_t
\end{equation}

với $\mathbf{u}_t = [v_{\text{cmd}}, \omega_{\text{cmd}}]$ và $\mathbf{w}_t \sim \mathcal{N}(0, \mathbf{Q})$. Process noise covariance $\mathbf{Q} = \text{diag}([0.01, 0.01, 0.005, 0.05, 0.05, 0.02])$ được chọn dựa trên thực nghiệm: pose có uncertainty thấp (odometry tương đối chính xác), velocity có uncertainty cao hơn (do slip và backlash).

\textbf{Measurement models} gồm 2 nguồn:

1. \textbf{IMU} (MPU6050) cung cấp gyroscope đo trực tiếp $\omega$ và accelerometer liên hệ với vận tốc. Measurement noise $\mathbf{R}_{\text{IMU}} = \text{diag}([0.1, 0.5, 0.5])$ phản ánh độ chính xác của sensor (gyro chính xác hơn accel).

2. \textbf{Wheel odometry} đo vận tốc bánh trái-phải, chuyển sang $(v, \omega)$ qua eq. \ref{eq:wheel_velocity}. Measurement noise $\mathbf{R}_{\text{odom}} = \text{diag}([0.01, 0.02])$ rất thấp do encoder có độ phân giải cao (15000 pulses/rev với tỷ số truyền 1:20). Do đó, trong UKF fusion, trọng số odometry được đặt cao hơn IMU (measurement noise thấp hơn 5-10 lần), ưu tiên tin cậy vào encoder thay vì gyro khi có xung đột giữa hai nguồn.

\subsection{Thuật toán UKF - Các bước chính}

UKF hoạt động qua 3 bước lặp lại mỗi chu kỳ:

\textbf{Bước 1 - Tạo sigma points:} Từ state estimate $\hat{\mathbf{x}}_t$ và covariance $\mathbf{P}_t$, tạo $2n+1 = 13$ sigma points (với $n=6$ dimensions) phân bố xung quanh $\hat{\mathbf{x}}_t$. Các điểm này được chọn sao cho khi tính mean và covariance của chúng sẽ khôi phục chính xác $\hat{\mathbf{x}}_t$ và $\mathbf{P}_t$:

\begin{equation}
\mathcal{X}_0 = \hat{\mathbf{x}}_t, \quad
\mathcal{X}_i = \hat{\mathbf{x}}_t \pm \left(\sqrt{(n+\lambda)\mathbf{P}_t}\right)_i
\end{equation}

với $\lambda$ là scaling parameter (chọn nhỏ để sigma points gần mean khi uncertainty thấp). Mỗi sigma point có weight tương ứng để tính mean và covariance.

\textbf{Bước 2 - Prediction:} Truyền từng sigma point qua process model $f(\cdot, \mathbf{u}_t)$ để được predicted sigma points, sau đó tính predicted state $\hat{\mathbf{x}}_{t+1|t}$ và covariance $\mathbf{P}_{t+1|t}$ bằng weighted sum của các điểm này cộng với process noise $\mathbf{Q}$. Đây là lúc UKF thể hiện ưu thế: thay vì linearize $f$, UKF truyền các điểm thực qua hàm phi tuyến nên giữ được nonlinearity.

\textbf{Bước 3 - Update:} Khi có measurement $\mathbf{z}_{t+1}$ từ IMU hoặc odometry, truyền predicted sigma points qua measurement model $h(\cdot)$ để dự đoán measurement $\hat{\mathbf{z}}_{t+1|t}$. Tính innovation (sai lệch giữa measurement thực và dự đoán), sau đó update state với Kalman gain:

\begin{equation}
\hat{\mathbf{x}}_{t+1} = \hat{\mathbf{x}}_{t+1|t} + \mathbf{K}(\mathbf{z}_{t+1} - \hat{\mathbf{z}}_{t+1|t})
\end{equation}

Kalman gain $\mathbf{K}$ cân bằng giữa tin tưởng vào prediction và tin tưởng vào measurement dựa trên uncertainty của chúng.

\subsection{So sánh với EKF và raw odometry}

\textbf{UKF vs EKF:} (1) UKF không cần tính Jacobian - tiết kiệm effort cho nonlinear models phức tạp, (2) Approximation chính xác hơn cho high nonlinearity, (3) Accuracy tương đương EKF bậc 2 nhưng với complexity tương đương EKF bậc 1. Trong thực nghiệm sơ bộ trên trajectory với nhiều góc rẽ gấp, UKF cho position error trung bình thấp hơn EKF khoảng 15-20\%.

\textbf{UKF vs Raw odometry:} Wheel odometry bị ảnh hưởng bởi slip, backlash, và không đo được lateral slip (drift theo trục y). IMU fusion giúp correct cho các lỗi này, đặc biệt gyro giúp estimate $\theta$ chính xác hơn nhiều. Trade-off: UKF có computational cost cao hơn 5-10x nhưng với Jetson Nano, update frequency 50 Hz vẫn khả thi.

\section{Triển khai Cartographer SLAM}
\label{sec:cartographer_implementation}

Phần này trình bày chi tiết triển khai Google Cartographer cho robot thực tế, bao gồm quy trình mapping, tinh chỉnh tham số, chuyển đổi sang chế độ localization, và các công cụ debug. Lý thuyết thuật toán Cartographer được trình bày trong Chương \ref{chap:overview} Mục \ref{subsec:cartographer_slam}.

\subsection{Quy trình Mapping}
\label{subsec:mapping_workflow}

Quy trình tạo bản đồ (mapping) sử dụng Cartographer bao gồm các bước: cấu hình file Lua, khởi chạy ROS launch, giám sát quá trình mapping qua RViz, và lưu bản đồ dưới dạng file \texttt{.pbstream}.

\textbf{Cấu hình file Lua:} File cấu hình chính \texttt{robot\_2d.lua} nằm trong thư mục \texttt{config/cartographer/}. Các thiết lập quan trọng bao gồm:
\begin{lstlisting}[basicstyle=\small\ttfamily, caption={Cấu hình Cartographer cho mapping}, label={lst:carto_mapping}]
options = {
  tracking_frame = "dummy_base_link",  -- Frame robot
  odom_frame = "robot_0/odom",         -- Odometry tu UKF
  use_odometry = true,                 -- Su dung UKF odom
  num_laser_scans = 1,                 -- 1 LiDAR 360 do
  use_imu_data = false,                -- IMU da tich hop trong UKF
}
MAP_BUILDER.use_trajectory_builder_2d = true
\end{lstlisting}

\textbf{Khởi chạy mapping:} Sử dụng ROS launch để khởi động Cartographer node:
\begin{verbatim}
roslaunch robot_controller cartographer_mapping.launch
\end{verbatim}

Trong quá trình mapping, cần điều khiển robot di chuyển chậm (tốc độ khuyến nghị 0.1-0.2 m/s) để LiDAR quét đủ chi tiết môi trường. Quan sát RViz để theo dõi các \textit{submap} được tạo ra và trajectory của robot.

\textbf{Lưu bản đồ:} Sau khi mapping hoàn tất, gọi service để kết thúc trajectory và lưu file:
\begin{verbatim}
rosservice call /finish_trajectory 0
rosservice call /write_state "filename: 'map.pbstream'"
\end{verbatim}

File \texttt{.pbstream} chứa toàn bộ submaps và pose graph, có thể load lại cho localization hoặc tiếp tục mapping.

\subsection{Quá trình Tinh chỉnh Tham số}
\label{subsec:param_tuning}

Việc tinh chỉnh tham số Cartographer cho phần cứng cụ thể (Jetson Nano + LiDAR LD19) đòi hỏi nhiều iteration thử nghiệm. Bảng \ref{tab:carto_params} tổng hợp các tham số quan trọng sau quá trình tinh chỉnh.

\textbf{Bối cảnh phần cứng:} Jetson Nano có 4GB RAM và 4 CPU cores, LiDAR LD19 quét 360° với tần số 10Hz và 455 điểm/vòng. Thách thức chính là cân bằng giữa chất lượng bản đồ và tài nguyên tính toán giới hạn.

\textbf{Iteration 1 - Vấn đề drift khi quay:} Với tham số mặc định, bản đồ bị "nhai" (drift) nghiêm trọng khi robot xoay tại chỗ. Nguyên nhân: \texttt{motion\_filter} quá nhạy, insert quá nhiều scan khi xoay. Giải pháp: tăng \texttt{max\_angle\_radians} từ 1° lên 3°.

\textbf{Iteration 2 - Vấn đề scan matching backward:} Robot di chuyển lùi không được match đúng. Nguyên nhân: \texttt{angular\_search\_window} quá hẹp (15°). Giải pháp: tăng lên 30° và giảm \texttt{rotation\_delta\_cost\_weight} từ 10.0 xuống 1.0.

\textbf{Iteration 3 - Vấn đề loop closure:} Khi gọi \texttt{finish\_trajectory}, optimization làm biến dạng bản đồ. Giải pháp: tắt hoàn toàn pose graph optimization bằng \texttt{optimize\_every\_n\_nodes = 0} và \texttt{sampling\_ratio = 0.0}.

\begin{table}[htbp]
\centering
\caption{Tham số Cartographer sau tinh chỉnh cho Jetson Nano + LiDAR LD19}
\label{tab:carto_params}
\begin{tabular}{p{5.5cm}p{2cm}p{6cm}}
\hline
\textbf{Tham số} & \textbf{Giá trị} & \textbf{Lý do và ảnh hưởng} \\
\hline
\multicolumn{3}{l}{\textit{Motion Filter}} \\
\texttt{max\_distance\_meters} & 0.05 & Update khi di chuyển 5cm, tăng độ chính xác \\
\texttt{max\_angle\_radians} & 0.5° & Update khi xoay 0.5°, tránh drift xoay \\
\hline
\multicolumn{3}{l}{\textit{Real-time Correlative Scan Matcher}} \\
\texttt{linear\_search\_window} & 0.15m & Tìm kiếm rộng 15cm, hỗ trợ di chuyển lùi \\
\texttt{angular\_search\_window} & 30° & Tìm kiếm mọi hướng, quan trọng cho robot differential \\
\texttt{translation\_delta\_cost\_weight} & 1.0 & Giảm penalty, linh hoạt hơn \\
\texttt{rotation\_delta\_cost\_weight} & 1.0 & Cho phép match khi xoay nhiều \\
\hline
\multicolumn{3}{l}{\textit{Ceres Scan Matcher}} \\
\texttt{occupied\_space\_weight} & 4.0 & Cân bằng giữa laser và odometry \\
\texttt{translation\_weight} & 60.0 & Tin tưởng odometry tịnh tiến \\
\texttt{rotation\_weight} & 40.0 & Tin tưởng odometry xoay \\
\texttt{max\_num\_iterations} & 14 & Giảm để tiết kiệm CPU \\
\hline
\multicolumn{3}{l}{\textit{Submap Configuration}} \\
\texttt{num\_range\_data} & 200 & Submap lớn, bao phủ mọi hướng \\
\texttt{resolution} & 0.04m & Độ phân giải 4cm, đủ chi tiết \\
\hline
\multicolumn{3}{l}{\textit{Pose Graph (Tắt hoàn toàn)}} \\
\texttt{optimize\_every\_n\_nodes} & 0 & Tắt optimization để tránh phá map \\
\texttt{sampling\_ratio} & 0.0 & Không tạo constraint mới \\
\hline
\end{tabular}
\end{table}

\subsection{Quy trình Navigation/Localization}
\label{subsec:navigation_workflow}

Sau khi có bản đồ (\texttt{.pbstream}), chuyển sang chế độ \textit{pure localization} để robot định vị trong bản đồ có sẵn mà không tạo submap mới.

\textbf{File cấu hình localization:} File \texttt{robot\_2d\_localization.lua} kế thừa từ \texttt{robot\_2d.lua} với các thay đổi:
\begin{lstlisting}[basicstyle=\small\ttfamily, caption={Cấu hình Cartographer cho localization}, label={lst:carto_localization}]
include "robot_2d.lua"

-- Bat che do pure localization
TRAJECTORY_BUILDER.pure_localization = true

-- Giam tan suat update (tiet kiem CPU)
motion_filter.max_distance_meters = 0.1   -- 10cm
motion_filter.max_angle_radians = 2.0 deg  -- 2 do

-- Giu pose graph o muc toi thieu
POSE_GRAPH.optimize_every_n_nodes = 5
POSE_GRAPH.constraint_builder.sampling_ratio = 0.1
\end{lstlisting}

\textbf{Khởi chạy localization:}
\begin{verbatim}
roslaunch robot_controller cartographer_localization.launch \
  load_state_filename:=/path/to/map.pbstream
\end{verbatim}

Robot sẽ tự động match scan hiện tại với bản đồ và publish pose qua topic \texttt{/robot\_0/tracked\_pose}. Chế độ localization tiêu tốn khoảng 10-15\% CPU (so với 25-30\% khi mapping), phù hợp cho Jetson Nano chạy đồng thời với model inference.

\subsection{Công cụ Debug và Tinh chỉnh}
\label{subsec:debug_tools}

Cartographer cung cấp các công cụ hỗ trợ debug và kiểm tra chất lượng:

\textbf{1. cartographer\_rosbag\_validate:} Kiểm tra tính hợp lệ của rosbag trước khi chạy Cartographer:
\begin{verbatim}
rosrun cartographer_ros cartographer_rosbag_validate \
  -bag_filename test.bag
\end{verbatim}
Tool này kiểm tra: timestamps đồng bộ, TF tree hợp lệ, message frequency ổn định. Nếu phát hiện lỗi, cần sửa driver sensor hoặc TF publisher.

\textbf{2. RViz State Visualization:} Trong RViz, thêm các display:
\begin{itemize}[nosep]
\item \textit{Submaps}: Hiển thị từng submap với màu khác nhau, kiểm tra overlap
\item \textit{Trajectory}: Đường đi của robot, kiểm tra drift
\item \textit{Constraints}: Các constraint giữa submaps (nếu bật optimization)
\end{itemize}
Dấu hiệu bất thường: submap chồng lấn không khớp, trajectory nhảy đột ngột, constraint kéo sai hướng.

\textbf{3. pbstream Inspection:} Kiểm tra file bản đồ đã lưu:
\begin{verbatim}
rosrun cartographer_ros cartographer_pbstream_map_publisher \
  -pbstream_filename map.pbstream
\end{verbatim}
Publish bản đồ dạng \texttt{OccupancyGrid} để visualize trong RViz mà không cần chạy full Cartographer.

Tài liệu tham khảo chi tiết về tuning và debugging: \cite{cartographer_tuning}

\section{Triển khai hệ robot hoàn chỉnh}
\label{sec:system_deployment}

Phần này trình bày kiến trúc hệ thống hoàn chỉnh bao gồm phần cứng, cấu hình mạng ROS, phân bổ các module, và giải thích cách hệ thống đảm bảo tính phi tập trung mặc dù inference được thực hiện tập trung.

\subsection{Kiến trúc tổng thể}

\begin{figure}[!t]
\centering
\resizebox{0.95\textwidth}{!}{
\begin{tikzpicture}[
    node distance=1.2cm,
    box/.style={rectangle, draw, minimum width=2.5cm, minimum height=0.8cm, align=center, font=\small, thick},
    master/.style={box, fill=blue!20},
    jetson/.style={box, fill=green!20},
    arduino/.style={box, fill=orange!20},
    sensor/.style={box, fill=yellow!20},
    arrow/.style={->, >=stealth, very thick},
    dasharrow/.style={->, >=stealth, thick, dashed, blue!60}
]

% Master PC
\node[master, minimum width=6cm, minimum height=3cm] (master) at (0,0) {};
\node[above=0.1cm of master.north, font=\small\bfseries] {Master PC};
\node[font=\scriptsize] at (master.north) [yshift=-0.4cm] {i7-11800H, 16GB RAM, GTX-3050};

\node[box, fill=blue!10, minimum width=2.2cm] (carto) at (-1.5, 0.3) {Cartographer\\SLAM};
\node[box, fill=blue!10, minimum width=2.2cm] (model) at (-1.5, -0.5) {Model\\Inference};
\node[box, fill=blue!10, minimum width=2.2cm] (rviz) at (1.2, -0.1) {RViz\\Monitoring};

% Robot 1 - Jetson Nano
\node[jetson, fill=gray!10, minimum width=3.5cm, minimum height=5cm] (jetson1) at (-5, -5) {};
\node[above=0.1cm of jetson1.north, font=\small\bfseries] {Robot 1 - Jetson Nano};
\node[font=\scriptsize] at (jetson1.north) [yshift=-0.4cm] {4GB RAM, 128 CUDA cores};

\node[sensor, minimum width=2.8cm] (lidar1) at (-5, -3.5) {LiDAR 360°\\455 beams};
\node[sensor, minimum width=2.8cm] (imu1) at (-5, -4.3) {IMU\\MPU6050};
\node[jetson, minimum width=2.8cm] (ukf1) at (-5, -5.1) {UKF\\Serial};

% Robot 1 - Arduino
\node[arduino, minimum width=2.5cm, minimum height=1.2cm] (arduino1) at (-5, -6.7) {Arduino};
\node[box, fill=orange!10, minimum width=2.2cm, font=\scriptsize] (pid1) at (-5, -6.8) {PID\\Motor};

% Robot 2 - Jetson Nano
\node[jetson, fill=gray!10,, minimum width=3.5cm, minimum height=5cm] (jetson2) at (5, -5) {};
\node[above=0.1cm of jetson2.north, font=\small\bfseries] {Robot 2 - Jetson Nano};
\node[font=\scriptsize] at (jetson2.north) [yshift=-0.4cm] {4GB RAM, 128 CUDA cores};

\node[sensor, minimum width=2.8cm] (lidar2) at (5, -3.5) {LiDAR 360°\\455 beams};
\node[sensor, minimum width=2.8cm] (imu2) at (5, -4.3) {IMU\\MPU6050};
\node[jetson, minimum width=2.8cm] (ukf2) at (5, -5.1) {UKF\\Serial};

% Robot 2 - Arduino
\node[arduino, minimum width=2.5cm, minimum height=1.2cm] (arduino2) at (5, -6.7) {Arduino};
\node[box, fill=orange!10, minimum width=2.2cm, font=\scriptsize] (pid2) at (5, -6.8) {PID\\Motor};

% ROS Network connection
\draw[dasharrow, <-] (master.south) -- ++(0,-0.8) node[midway, right, font=\tiny] {WiFi} -- ++(-5,0) |- (jetson1.north);
\draw[dasharrow, <-] (master.south) -- ++(0,-0.8) -- ++(5,0) |- (jetson2.north);

% Robot 1 data flow
\draw[arrow, red!70, thick] (master) -- ++(-3.0,-5) node[midway, left, font=\tiny] {cmd\_vel} |- (jetson1.east);
\draw[arrow] (ukf1) -- (arduino1) node[midway, right, font=\tiny] {serial};

% Robot 2 data flow
\draw[arrow, red!70, thick] (master) -- ++(3,-5) node[midway, right, font=\tiny] {cmd\_vel} |- (jetson2.west);
\draw[arrow] (ukf2) -- (arduino2) node[midway, left, font=\tiny] {serial};

% Notes
\node[below=1.0cm of master, font=\scriptsize, text width=6cm, align=center] {Static IP: 192.168.1.100\\ROS\_MASTER\_URI};
\node[below=0.1cm of jetson1, font=\scriptsize, text width=3cm, align=center] {Static IP:\\192.168.1.101};
\node[below=0.1cm of jetson2, font=\scriptsize, text width=3cm, align=center] {Static IP:\\192.168.1.102};

\end{tikzpicture}
}
\caption{Kiến trúc hệ thống đa robot hoàn chỉnh}
\label{fig:system_architecture}
\end{figure}

Hệ thống bao gồm 1 Master PC và 2 robot tự hành (mỗi robot có 1 Jetson Nano làm bộ xử lý chính). Kiến trúc được thiết kế theo nguyên tắc \textbf{decentralized} về mặt algorithm, trong đó mỗi robot đưa ra quyết định độc lập dựa trên quan sát cục bộ của chính nó, không có inter-robot communication.

\subsection{Cấu hình phần cứng}

Bảng \ref{tab:hardware_config} liệt kê cấu hình phần cứng của các thành phần chính trong hệ thống.

\begin{table}[htbp]
\centering
\caption{Cấu hình phần cứng hệ thống}
\label{tab:hardware_config}
\begin{tabular}{lll}
\hline
\textbf{Thiết bị} & \textbf{Thông số} & \textbf{Vai trò} \\
\hline
Master PC & Intel i7-11800H & Cartographer SLAM \\
          & 16GB RAM & Model inference \\
          & GTX-3050, ROS Noetic & ROS Master node \\
          & Ubuntu 20.04 &  \\
\hline
Jetson Nano & 4GB RAM & Lấy dữ liệu sensor \\
            & Maxwell 128 CUDA cores & Fuse sensor với UKF \\
            & Ubuntu 18.04, ROS Melodic & Serial communication \\
\hline
Arduino  & ATmega328P & Điều khiển động cơ PID \\
             & 16 MHz & Đọc vận tốc bánh xe \\
\hline
LiDAR 360° & Quét 360° & Phát hiện vật cản \\
                & Độ phân giải 455 tia & SLAM \\
\hline
IMU MPU6050 & 3-axis gyro + accel & Ước lượng vị trí \\
                 & I2C interface &  \\
\hline
Động cơ DC  & Encoder 15000 pulses/rev & Điều hướng robot \\
            & Tỷ số truyền 1:20 &  \\
\hline
\end{tabular}
\end{table}

\subsection{Cấu hình mạng ROS}

Hệ thống sử dụng ROS network qua WiFi với cấu hình tĩnh (static IP) để đảm bảo kết nối ổn định. Master PC đóng vai trò ROS Master node, quản lý tất cả topics và services.

\textbf{Cấu hình IP tĩnh:}
\begin{itemize}[nosep]
\item Master PC: 192.168.1.100 (ROS\_MASTER\_URI = http://192.168.1.100:11311)
\item Robot 1 (Jetson Nano): 192.168.1.101
\item Robot 2 (Jetson Nano): 192.168.1.102
\end{itemize}

Mỗi máy cần export biến môi trường ROS:
\begin{verbatim}
export ROS_MASTER_URI=http://192.168.1.100:11311
export ROS_IP=<địa chỉ IP của máy hiện tại>
\end{verbatim}

\subsection{Phân bổ các ROS nodes}

Bảng \ref{tab:node_distribution} mô tả phân bổ các ROS nodes trên các thiết bị khác nhau.

\begin{table}[htbp]
\centering
\caption{Phân bổ ROS nodes trên các thiết bị}
\label{tab:node_distribution}
\begin{tabular}{lll}
\hline
\textbf{Node} & \textbf{Chạy trên} & \textbf{Topics chính} \\
\hline
\texttt{cartographer\_node} & Master PC & Subscribe: /robot\_X/scan, /robot\_X/imu \\
                            &           & Publish: /robot\_X/amcl\_pose \\
\hline
\texttt{policy\_node} & Master PC & Subscribe: /robot\_X/scan, /robot\_X/amcl\_pose \\
                      &           & Publish: /robot\_X/cmd\_vel \\
\hline
\texttt{lidar\_node} & Jetson Nano & Publish: /robot\_X/scan \\
\hline
\texttt{imu\_node} & Jetson Nano & Publish: /robot\_X/imu \\
\hline
\texttt{ukf\_node} & Jetson Nano & Subscribe: /robot\_X/imu, /robot\_X/cmd\_vel \\
                   &             & Publish: /robot\_X/odom \\
\hline
\texttt{serial\_node} & Jetson Nano & Subscribe: /robot\_X/cmd\_vel \\
                      &             & Serial output: Arduino \\
\hline
PID Controller & Arduino & Serial input: target velocity \\
               &         & PWM output: motor driver \\
\hline
\end{tabular}
\end{table}

\textbf{Luồng dữ liệu chính:}
\begin{enumerate}[nosep]
\item LiDAR và IMU trên Jetson publish sensor data qua ROS topics
\item Master PC nhận sensor data, chạy Cartographer để estimate pose
\item Policy node trên Master PC inference action $(v, \omega)$ từ observations
\item Master publish cmd\_vel về Jetson qua ROS network
\item Jetson forward cmd\_vel xuống Arduino qua serial (USB)
\item Arduino chạy PID controller và điều khiển động cơ qua PWM
\end{enumerate}

Tần số điều khiển: \textbf{20 Hz} (mỗi 50ms một control cycle), đảm bảo real-time response cho collision avoidance.

\subsection{Thiết kế phi tập trung mặc dù inference tập trung}
\label{subsec:decentralized_design}

\textbf{Phân biệt giữa Design và Implementation:}

Hệ thống được \textbf{thiết kế decentralized hoàn toàn} về mặt algorithm. Cụ thể:
\begin{itemize}[nosep]
\item Mỗi robot quyết định hành động dựa \textbf{CHỈ} trên quan sát cục bộ của chính nó: LiDAR scan, vị trí đích riêng, và vận tốc hiện tại
\item \textbf{Không có inter-robot communication}: Robot A không biết Robot B đang làm gì, đang đi đâu, hay có ý định gì
\item Robot B được Robot A nhận biết như một \textbf{dynamic obstacle} thông qua LiDAR scan, tương tự như tường hoặc vật cản khác
\item Policy network của mỗi robot hoàn toàn độc lập - không có shared parameters hay coordination mechanism
\end{itemize}

Việc inference chạy trên Master PC là \textbf{implementation choice do hạn chế phần cứng}, không phải design limitation. Cụ thể:
\begin{itemize}[nosep]
\item Jetson Nano chỉ có 4GB RAM và GPU yếu (Maxwell 128 CUDA cores)
\item Model inference trên Jetson mất 50-100ms, so với ~10ms trên Master PC i7
\item Latency cao gây chậm trễ không chấp nhận được cho real-time collision avoidance (20 Hz)
\end{itemize}

\textbf{Tính scalable và decentralized deployment:}

Code không có bất kỳ dependency nào với Master PC về mặt thiết kế. Tất cả topics cần thiết (\texttt{/robot\_X/scan}, \texttt{/robot\_X/amcl\_pose}, \texttt{/robot\_X/move\_base\_simple/goal}) đều có thể chạy local trên từng robot. Với phần cứng mạnh hơn (Jetson Orin có 32GB RAM và Ampere GPU, hoặc mini PC), toàn bộ pipeline (SLAM + model inference) có thể deploy hoàn toàn decentralized mà \textbf{không cần thay đổi code}, chỉ cần sửa launch file để các nodes chạy local thay vì remote.

Kiến trúc ROS cho phép linh hoạt di chuyển nodes giữa các máy chỉ bằng cách thay đổi \texttt{machine} tag trong launch file:
\begin{verbatim}
<!-- Hiện tại: inference trên Master -->
<node pkg="robot_controller" type="run_model_safe.py"
      name="policy_node" machine="master"/>

<!-- Tương lai: inference local trên robot -->
<node pkg="robot_controller" type="run_model_safe.py"
      name="policy_node" machine="robot_1"/>
\end{verbatim}

\textbf{So sánh với paper gốc:} Long et al. (2018) \cite{long2018towards} thiết kế algorithm decentralized và deploy decentralized trên simulation. Implementation này giữ nguyên algorithm decentralized nhưng deploy centralized do hardware constraints - vẫn đúng với tinh thần của paper.

\subsection{Tóm tắt deployment}

Hệ thống triển khai hoàn chỉnh bao gồm:
\begin{itemize}[nosep]
\item Kiến trúc Master-Slave với ROS network qua WiFi (static IP)
\item Master PC (i7-11800H, 15GB RAM) chạy Cartographer SLAM và model inference
\item 2 robots với Jetson Nano xử lý sensors, UKF fusion, và serial communication
\item Arduino chạy PID controllers tầng thấp cho motor control
\item Control loop 20 Hz đảm bảo real-time collision avoidance
\item Thiết kế decentralized algorithm với centralized inference (implementation choice)
\item Scalable: có thể chuyển sang fully decentralized deployment với hardware upgrade
\end{itemize}

